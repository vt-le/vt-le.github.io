
<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Viet-Tuan Le (Felix)</title>
<meta name="description" content="Viet-Tuan Le's website">

<!-- Open Graph --> 


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="css/main.css">

<link rel="canonical" href="/">


<!-- Theming-->


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="row ml-1 ml-sm-0">
          <span class="contact-icon text-center">
  <a href="mailto:tuanlv@sju.ac.kr"><i class="fas fa-envelope"></i></a>
  
  <a href="https://scholar.google.com/citations?user=vje71PYAAAAJ&hl=en" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
  
  
  <a href="https://github.com/vt-le" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
  <a href="#" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
  <a href="#" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
  
  
  
  
</span>

        </div>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="index.html">
              About
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>

          <li class="nav-item ">
              <a class="nav-link" href="#">
                CV                
              </a>
          </li>

          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="#">
              blog
              
            </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

<div class="container mt-5">
  <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Viet-Tuan Le (Felix)</span>
    </h1>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1" src="./images/tuanlv.jpg">
      
      
    </div>
    

    <div class="clearfix">
      <p> I am a Research Scientist at Human-Computer Interaction (HCI) Laboratory. I am mainly interested in <b>video anomaly detection</b> and <b>generative models</b>. Specifically, I work on anomaly detection in video using attention mechanism, transformers and diffusion models. I also work on Prohibited Item Detection in X-ray images. I obtained my Ph.D. in <a href="http://en.sejong.ac.kr/eng/index.do">Sejong University,</a> advised by <a href="http://home.sejong.ac.kr/~ykim/">Yong-Guk Kim</a>. Prior to that, I received my Master degree of Computer Science from <a href="https://en.hcmus.edu.vn/">University of Science - VNUHCM</a>, advised by <a href="https://scholar.google.com/citations?hl=en&user=MskoD4gAAAAJ">Ngoc Quoc Ly</a>.  </p> 

      <p> <strong>Contact:</strong> <span style="font-family:'Lucida Console', monospace">vt-le at outlook dot com</span> 
      </div>
  </article>
<p><strong>News:</strong> </p>
<ul>
    <li>[1/03/2025] <a href="https://vt-le.github.io/HSTforU/">HSTforU</a> is available online.</li>
    <li>[9/20/2023] <a href="https://github.com/vt-le/FusedAnomaly">FusedAnomaly</a></li>
    <li>[1/18/2023] <a href="https://vt-le.github.io/HSTforU/">HSTforU</a> is released.</li>
    <li>[5/25/2022] <a href="https://vt-le.github.io/astnet/">ASTNet</a> is available online.</li>
    <li>[4/21/2022] Code of <a href="https://vt-le.github.io/astnet/">ASTNet</a> is released.</li>
    <li>[4/09/2022] <a href="https://vt-le.github.io/astnet/">ASTNet</a> is accepted by <a href="https://www.springer.com/journal/10489/">Applied Intelligence.</a></li>
</ul>

<p><strong>Selected publications:</strong> </p>

<article>
  <!-- An up-to-date list is available on <a href="https://scholar.google.com/citations?user=VdlgOXoAAAAJ&hl=en" target="\_blank">Google Scholar</a> -->
<div class="publications">

  <ol class="bibliography">


    <li><div class="row">
      <div class="col-sm-2 abbr">
        <abbr class="badge">Journal</abbr>
      </div>
    
      <div id="le2024mogup" class="col-sm-8">
        
          <div class="title">FusedAnomaly</div>
          <div class="author">
                <em>Viet-Tuan Le</em> and <a href="http://home.sejong.ac.kr/~ykim/">Yong-Guk Kim</a>
            
          </div>
          <div class="periodical">    
            Under submission
          </div>
          <!--
       <div class="periodical">    
            <em><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">IEEE Transactions on Circuits and Systems for Video Technology</a></em>, 2023
          </div>  -->
    
        <div class="links">
          <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          <a href="#" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
          <a href="https://github.com/vt-le/FusedAnomaly" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
          <a href="https://github.com/vt-le/FusedAnomaly" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
          <img src="https://img.shields.io/github/stars/vt-le/FusedAnomaly=social">
        </div>
    
        <!-- Hidden abstract block -->
        <div class="abstract hidden">
          <p>Video anomaly detection aims to identify abnormal events occurring sporadically amid prevalent normal activities within surveillance footage. In pursuit of this, numerous existing methods learn the patterns of normal events by predicting or reconstructing frames based on preceding sequences. However, these methods often generate both normal and abnormal events with high fidelity, making it difficult to distinguish anomalies effectively.
Some approaches utilize a two-stream network to extract spatial and motion information. In these methods, spatial and temporal streams operate independently, with limited interaction or information exchange. 
To address these limitations, we propose a video anomaly detection that consists of an attention-based reconstruction network for modeling motion information and spatio-temporal fusion. to model motion information by reconstructing a single optical flow frame aligned with the corresponding ground truth frame. To integrate spatial and temporal features, we also propose a cross-model generation module that effectively combines spatial and motion features. 
Extensive evaluations, including ablation studies, suggest that our approach outperforms the state-of-the-art methods on three standard benchmark datasets: UCSD Ped2, CUHK Avenue, and ShanghaiTech. These results highlight the framework's potential for a wide range of video processing applications. The code and pretrained models are available at <a href="https://github.com/vt-le/CrossAnomaly">https://github.com/vt-le/CrossAnomaly</a>.</p>
        </div>
      </div>
    </div>
    </li>
  </ol>


<!-- <h2 class="year">2023</h2> -->
<ol class="bibliography">

<li><div class="row">
<div class="col-sm-2 abbr">
  <abbr class="badge">Journal</abbr>
</div>

<!--HSTforU-->
<div id="le2023hstforu" class="col-sm-8">
  
    <div class="title">HSTforU: Anomaly Detection in Aerial and Ground-based Videos with Hierarchical Spatio-Temporal Transformer for U-net</div>
    <div class="author">
              <em>Viet-Tuan Le</em>, Hulin Jin, and <a href="http://home.sejong.ac.kr/~ykim/">Yong-Guk Kim</a>
      
    </div>
    <div class="periodical">    
      <em><a href="https://link.springer.com/article/10.1007/s10489-024-06042-4">Applied Intelligence</a></em>, 2025
    </div>
  <!--
 <div class="periodical">    
      <em><a href="https://www.sciencedirect.com/journal/expert-systems-with-applications">Expert Systems with Applications</a></em>, 2023
    </div>  -->

  <div class="links">
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    <a href="https://link.springer.com/content/pdf/10.1007/s10489-024-06042-4.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
    <a href="https://vt-le.github.io/HSTforU/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    <a href="https://github.com/vt-le/HSTforU" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    <img src="https://img.shields.io/github/stars/vt-le/HSTforU?style=social">
    
  </div>

  <!-- Hidden abstract block -->
  <div class="abstract hidden">
    <p>Anomaly detection is to identify abnormal events against normal ones within surveillance videos mainly collected in ground-based settings. Recently, the demand for processing drone-collected data is rapidly growing with the expanding range of drone applications. However, as most aerial videos collected by flying drones contain dynamic backgrounds and others, it is necessary to deal with their spatio-temporal features in detecting anomalies. This study presents a transformer-based video anomaly detection method whereby we investigate a challenging aerial dataset and three benchmark ground-based datasets. A multi-stage transformer is leveraged as an encoder to generate multi-scale feature maps, which are then conveyed to a hierarchical spatio-temporal transformer, that is linked to a decoder and used to capture spatial and temporal information by utilizing a joint attention mechanism. Extensive evaluations including several ablation studies suggest that this network outperforms the state-of-the-art methods. We expect the proposed transformer for U-net can find diverse applications in the video processing area. Code and pre-trained models are publicly available at <a href="https://github.com/vt-le/HSTforU">https://github.com/vt-le/HSTforU</a>.</p>
  </div>
</div>
<!--HSTforU-->
</div>
</li>


</ol>

<!-- <h2 class="year">2022</h2> -->
<ol class="bibliography">

<li>
  <div class="row">
  <div class="col-sm-2 abbr">
    <abbr class="badge">Journal</abbr>
  </div>

  <div id="le2022attention" class="col-sm-8">
    
      <div class="title">Attention-based Residual Autoencoder for Video Anomaly Detection</div>
      <div class="author">
                <em>Viet-Tuan Le</em> and <a href="http://home.sejong.ac.kr/~ykim/">Yong-Guk Kim</a>
        
      </div>
   <div class="periodical">    
        <em><a href="https://www.springer.com/journal/10489">Applied Intelligence</a></em>, 2023
      </div>  

    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://link.springer.com/content/pdf/10.1007/s10489-022-03613-1.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      <a href="https://vt-le.github.io/astnet/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
      <a href="https://github.com/vt-le/astnet" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      <img src="https://img.shields.io/github/stars/vt-le/astnet?style=social">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Automatic anomaly detection is a crucial task in video surveillance system intensively used for public safety and others. The present system adopts a spatial branch and a temporal branch in a unified network that exploits both spatial and temporal information effectively. The network has a residual autoencoder architecture, consisting of a deep convolutional neural network-based encoder and a multi-stage channel attention-based decoder, trained in an unsupervised manner. The temporal shift method is used for exploiting the temporal feature, whereas the contextual dependency is extracted by channel attention modules. System performance is evaluated using three standard benchmark datasets. Result suggests that our network outperforms the state-of-the-art methods, achieving 97.4% for UCSD Ped2, 86.7% for CUHK Avenue, and 73.6% for ShanghaiTech dataset in term of Area Under Curve, respectively.</p>
    </div>
  </div>
  </div>
</li>
</ol>
</div>


</article>

<p><strong>Review Services:</strong> </p>
Reviewer
<ul>
  <li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">IEEE Transactions on Circuits and Systems for Video Technology</a></li>
  <li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE Transactions on Neural Networks and Learning Systems</a></li>  
  <li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE Transactions on Image Processing</a></li>
  <li><a href="https://www.springer.com/journal/530">Multimedia Systems</a></li>
  <li><a href="https://www.springer.com/journal/10586">Cluster Computing</a></li>
  <li><a href="https://www.springer.com/journal/11760">Signal, Image and Video Processing</a></li>
  <li><a href="https://link.springer.com/journal/13042">International Journal of Machine Learning and Cybernetics</a></li>

</ul>
Program Committee Member
<ul>
  <li>International Conference on Intelligence of Things (ICIT): <a href="https://icit2022.humg.edu.vn/technical-committee/">2022</a>, <a href="https://cse.hcmut.edu.vn/icit2023/committee.php">2023</a>, <a href="https://icitconf.org/">2024</a>, <a href="https://icitconf.org/">2025</a></li>
  <li><a href="https://eidt.ou.edu.vn/">International Conference on Explainable Intelligence in Digital Twins (EIDT), 2025</a></li>
  
</ul>


</div>

</div>
<!-- Footer -->
<div>
  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=15CZ1IaogB1ZZGskepBnoDeGkujyRZFQPgr6odf5Xv4'></script>
</div>

</body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Global site tag (gtag.js) - Google Analytics -->
<!-- It will be added later-->


<!-- Load Common JS -->
<script src="./js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="./js/dark_mode.js"></script>


</html>
